{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2595c14e-e3be-4071-a03f-0916b9d9e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from datetime import datetime\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e2de2b-7e43-453c-a874-5b9b16b76e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/home/sakkarouis/Downloads/ner_description_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdcdfc88-44e1-40c6-80a6-f01ef0b1669d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je suis Honor√© Allard, n√©(e) le 30 January 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je suis Roland Teixeira, n√©(e) le 17 June 1995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Je suis Fran√ßoise Gosselin, n√©(e) le 15 August...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Je suis Olivier Seguin, n√©(e) le 18 October 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je suis Alfred Lopes-Dupont, n√©(e) le 22 March...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Je suis Anouk Roche, n√©(e) le 20 March 2001, √©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Je suis No√©mi-Anne Buisson, n√©(e) le 8 Februar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Je suis Matthieu Leblanc, n√©(e) le 19 February...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Je suis Hortense Robert, n√©(e) le 08/03/1995, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Je suis Vincent Vidal, n√©(e) le 19/03/1996, √©t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Je suis Honor√© Allard, n√©(e) le 30 January 200...\n",
       "1    Je suis Roland Teixeira, n√©(e) le 17 June 1995...\n",
       "2    Je suis Fran√ßoise Gosselin, n√©(e) le 15 August...\n",
       "3    Je suis Olivier Seguin, n√©(e) le 18 October 19...\n",
       "4    Je suis Alfred Lopes-Dupont, n√©(e) le 22 March...\n",
       "..                                                 ...\n",
       "295  Je suis Anouk Roche, n√©(e) le 20 March 2001, √©...\n",
       "296  Je suis No√©mi-Anne Buisson, n√©(e) le 8 Februar...\n",
       "297  Je suis Matthieu Leblanc, n√©(e) le 19 February...\n",
       "298  Je suis Hortense Robert, n√©(e) le 08/03/1995, ...\n",
       "299  Je suis Vincent Vidal, n√©(e) le 19/03/1996, √©t...\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5d051-89e9-4331-9e80-4b59a3993b12",
   "metadata": {},
   "source": [
    "## EDA & DATA CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a15d3d5-b22e-42d3-887d-d6048de9b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # enlever les accents\n",
    "    text = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', text)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "    # supprimer les espaces multiples\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8138a13a-922a-415a-a9dd-a54db6c6029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clear'] = df['text'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff77e135-cc8d-4ced-a64d-8f3f2ce1aa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Je suis Anouk Roche, n√©(e) le 20 March 2001, √©...</td>\n",
       "      <td>Je suis Anouk Roche, ne(e) le 20 March 2001, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Je suis No√©mi-Anne Buisson, n√©(e) le 8 Februar...</td>\n",
       "      <td>Je suis Noemi-Anne Buisson, ne(e) le 8 Februar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Je suis Matthieu Leblanc, n√©(e) le 19 February...</td>\n",
       "      <td>Je suis Matthieu Leblanc, ne(e) le 19 February...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Je suis Hortense Robert, n√©(e) le 08/03/1995, ...</td>\n",
       "      <td>Je suis Hortense Robert, ne(e) le 08/03/1995, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Je suis Vincent Vidal, n√©(e) le 19/03/1996, √©t...</td>\n",
       "      <td>Je suis Vincent Vidal, ne(e) le 19/03/1996, et...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "295  Je suis Anouk Roche, n√©(e) le 20 March 2001, √©...   \n",
       "296  Je suis No√©mi-Anne Buisson, n√©(e) le 8 Februar...   \n",
       "297  Je suis Matthieu Leblanc, n√©(e) le 19 February...   \n",
       "298  Je suis Hortense Robert, n√©(e) le 08/03/1995, ...   \n",
       "299  Je suis Vincent Vidal, n√©(e) le 19/03/1996, √©t...   \n",
       "\n",
       "                                            text_clear  \n",
       "295  Je suis Anouk Roche, ne(e) le 20 March 2001, e...  \n",
       "296  Je suis Noemi-Anne Buisson, ne(e) le 8 Februar...  \n",
       "297  Je suis Matthieu Leblanc, ne(e) le 19 February...  \n",
       "298  Je suis Hortense Robert, ne(e) le 08/03/1995, ...  \n",
       "299  Je suis Vincent Vidal, ne(e) le 19/03/1996, et...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fc4542a-8921-41e3-8dea-fba77920510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_date(text):\n",
    "    months_en_fr = {\n",
    "        \"january\":\"01\", \"jan\":\"01\", \"janvier\":\"01\",\n",
    "        \"february\":\"02\", \"feb\":\"02\",\"fevrier\":\"02\",\n",
    "        \"march\":\"03\", \"mar\":\"03\",\"mars\":\"03\",\n",
    "        \"april\":\"04\", \"apr\":\"04\",\"avril\":\"04\",\n",
    "        \"may\":\"05\",\"mai\":\"05\",\n",
    "        \"june\":\"06\", \"jun\":\"06\",\"juin\":\"06\",\n",
    "        \"july\":\"07\", \"jul\":\"07\",\"juillet\":\"07\",\n",
    "        \"august\":\"08\", \"aug\":\"08\",\"aout\":\"08\",\n",
    "        \"september\":\"09\", \"sep\":\"09\",\"septembre\":\"09\",\n",
    "        \"october\":\"10\", \"oct\":\"10\",\"octobre\":\"10\",\n",
    "        \"november\":\"11\", \"nov\":\"11\",\"novembre\":\"11\",\n",
    "        \"december\":\"12\", \"dec\":\"12\",\"decembre\":\"12\"\n",
    "    }\n",
    "    \n",
    "    def replacer(match):\n",
    "        day, month, year = match.groups()\n",
    "        # Si month est num√©rique (02/01/2001)\n",
    "        if month.isdigit():\n",
    "            month_num = f\"{int(month):02d}\"\n",
    "        else:\n",
    "            month_num = months_en_fr.get(month.lower(), None)\n",
    "        return f\"{int(day):02d}-{month_num}-{year}\"\n",
    "    \n",
    "    # 1Ô∏è‚É£ jj/mm/aaaa\n",
    "    pattern1 = re.compile(r\"(\\d{1,2})/(\\d{1,2})/(\\d{4})\")\n",
    "    text = pattern1.sub(replacer, text)\n",
    "    \n",
    "    # 2Ô∏è‚É£ jj Month yyyy\n",
    "    pattern2 = re.compile(r\"(\\d{1,2})\\s([a-zA-Z]+)\\s(\\d{4})\")\n",
    "    text = pattern2.sub(replacer, text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f5201d1-a8bb-4ac9-b255-4a1a6c5e787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clear'] = df['text_clear'].apply(normalize_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311f6101-13a3-4324-b038-7fc7b524dd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Je suis Honore Allard, ne(e) le 30-01-2005, et...\n",
       "1      Je suis Roland Teixeira, ne(e) le 17-06-1995, ...\n",
       "2      Je suis Francoise Gosselin, ne(e) le 15-08-199...\n",
       "3      Je suis Olivier Seguin, ne(e) le 18-10-1995, e...\n",
       "4      Je suis Alfred Lopes-Dupont, ne(e) le 22-03-19...\n",
       "                             ...                        \n",
       "295    Je suis Anouk Roche, ne(e) le 20-03-2001, etud...\n",
       "296    Je suis Noemi-Anne Buisson, ne(e) le 08-02-200...\n",
       "297    Je suis Matthieu Leblanc, ne(e) le 19-02-1995,...\n",
       "298    Je suis Hortense Robert, ne(e) le 08-03-1995, ...\n",
       "299    Je suis Vincent Vidal, ne(e) le 19-03-1996, et...\n",
       "Name: text_clear, Length: 300, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_clear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11adcb-4eab-490b-af9c-402ad881264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (3.8.11)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (2.3.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (2.12.4)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/nlp_env/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting fr-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.8.0/fr_core_news_lg-3.8.0-py3-none-any.whl (571.8 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚ï∏\u001b[0m\u001b[38;5;237m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.4/571.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:04:42\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download fr_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198aa436-04fa-40fa-b309-59bea9723f6f",
   "metadata": {},
   "source": [
    "## NER using (SPACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f708071-2ae4-486d-87f1-0800139306b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad786ed-f973-4722-96af-0ce4813f783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"Je suis William Hernandez, n√© le 06-10-1998, √©tudiant √† IHEC Sousse, r√©sidant √† Sousse.\"\n",
    "#doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb587d02-11ba-4663-98fc-2dca619e06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "492e5c12-669f-4bf9-9e86-e6204530c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ent in doc.ents:\n",
    " #   print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e540c67c-88bb-4fb3-8558-2bbe94edf422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          text_clear  \\\n",
      "0  Je suis Honore Allard, ne(e) le 30-01-2005, et...   \n",
      "\n",
      "                                            entities  \n",
      "0  {'PER': ['Honore Allard'], 'LOC': ['Bizerte'],...  \n"
     ]
    }
   ],
   "source": [
    "# Fonction pour extraire les entit√©s\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {\"PER\": [], \"LOC\": [], \"ORG\": []}\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in entities:\n",
    "            entities[ent.label_].append(ent.text)\n",
    "    return entities\n",
    "\n",
    "# Appliquer sur tout le dataset\n",
    "df['entities'] = df['text_clear'].apply(extract_entities)\n",
    "\n",
    "# Voir un exemple\n",
    "print(df[['text_clear', 'entities']].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bb36691-2280-47c3-8d59-b1842df62ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email(text):\n",
    "    match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
    "    return match.group(0) if match else \"unknown\"\n",
    "\n",
    "def extract_phone(text):\n",
    "    match = re.search(r\"\\+?\\d[\\d\\s]{7,}\", text)\n",
    "    return match.group(0) if match else \"unknown\"\n",
    "\n",
    "def extract_birthdate(text):\n",
    "    pattern = r\"(\\d{2}-\\d{2}-\\d{4})\"\n",
    "def extract_location_regex(text):\n",
    "    # Cherche apr√®s 'r√©sidant', 'habite'\n",
    "    match = re.search(r\"(?:r√©sidant(?:e)?|habite)\\s+√†\\s+([A-Z][\\w\\s\\-']+)\", text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "    \n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(0) \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b28db1d-b339-4ce3-aa9b-0e6c959b4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_university_regex(text):\n",
    "    # Cherche apr√®s '√©tudiant', '√©tudier', 'inscrit'\n",
    "    match = re.search(r\"(?:√©tudiant(?:e)?|√©tudier|inscrit(?:e)?)\\s+(?:√†|en)\\s+([A-Z][\\w\\s\\-']+)\", text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6a21ed-2e56-40e3-8773-9010937adac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_regex(text):\n",
    "    # Cherche apr√®s 'r√©sidant', 'habite'\n",
    "    match = re.search(r\"(?:r√©sidant(?:e)?|habite)\\s+√†\\s+([A-Z][\\w\\s\\-']+)\", text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa5ab21f-286c-48a4-a498-07b46e2e4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_profile(text):\n",
    "    # spaCy NER\n",
    "    doc = nlp(text)\n",
    "\n",
    "    profile = {\"name\": \"unknown\", \"location\": \"unknown\", \n",
    "               \"university\": \"unknown\",\n",
    "               \"email\": \"unknown\", \"phone\": \"unknown\",\n",
    "               \"birthdate\": \"unknown\"}\n",
    "\n",
    "    # Liste de mots invalides pour le nom\n",
    "    invalid_person_words = [\"etudiant\", \"etudiante\", \"professeur\", \n",
    "                            \"ing√©nieur\", \"chercheur\", \"doctorant\", \"stagiaire\"]\n",
    "\n",
    "    # NER pour Location et University\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"LOC\":\n",
    "            profile[\"location\"] = ent.text\n",
    "        if ent.label_ == \"ORG\":\n",
    "            profile[\"university\"] = ent.text\n",
    "\n",
    "    # Fallback regex pour University et Location\n",
    "    uni_fallback = extract_university_regex(text)\n",
    "    if uni_fallback:\n",
    "        profile[\"university\"] = uni_fallback\n",
    "    \n",
    "    loc_fallback = extract_location_regex(text)\n",
    "    if loc_fallback:\n",
    "        profile[\"location\"] = loc_fallback\n",
    "\n",
    "    # üîπ Nom : priorit√© √† la regex \"Je suis / Je m'appelle\"\n",
    "    match_name = re.search(\n",
    "        r\"(?:Je m'appelle|Je suis)\\s+([A-Z][a-z]+(?:[-\\s][A-Z][a-z]+)*)\",\n",
    "        text\n",
    "    )\n",
    "    if match_name:\n",
    "        profile[\"name\"] = match_name.group(1)\n",
    "    else:\n",
    "        # Sinon, prendre le premier PER valide d√©tect√© par spaCy\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\":\n",
    "                if ent.text.lower() not in invalid_person_words:\n",
    "                    profile[\"name\"] = ent.text\n",
    "                    break\n",
    "\n",
    "    # Email\n",
    "    email_match = re.search(r\"[\\w\\.-]+@[\\w\\.-]+\", text)\n",
    "    if email_match:\n",
    "        profile[\"email\"] = email_match.group(0)\n",
    "    \n",
    "    # T√©l√©phone\n",
    "    phone_match = re.search(r\"\\+?\\d[\\d\\s]{7,}\", text)\n",
    "    if phone_match:\n",
    "        profile[\"phone\"] = phone_match.group(0)\n",
    "    \n",
    "    # Date de naissance\n",
    "    date_match = re.search(r\"(\\d{2}-\\d{2}-\\d{4})\", text)\n",
    "    if date_match:\n",
    "        profile[\"birthdate\"] = date_match.group(1)\n",
    "\n",
    "    return profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b050796-ad66-4c73-b3db-cd161cba309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Achraf Sakka Rouis',\n",
       " 'location': 'Sousse',\n",
       " 'university': 'Polytechnique',\n",
       " 'email': 'achraf.sr@gmail.com',\n",
       " 'phone': '+216 22 333 444',\n",
       " 'birthdate': '12-08-2002'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"Je suis Achraf Sakka Rouis etudiant √† Polytechnique, j'habite √† Sousse.Mon email est achraf.sr@gmail.com Je suis n√© le 12-08-2002. Mon num√©ro : +216 22 333 444.\"\n",
    "profile=build_profile(text)\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3db523d-4f48-439f-8e0f-c650b6a1963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "df['profile'] = df['text_clear'].apply(build_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82faaf9e-a879-4c1b-ad0c-17ca08289b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          text_clear  \\\n",
      "0  Je suis Honore Allard, ne(e) le 30-01-2005, et...   \n",
      "1  Je suis Roland Teixeira, ne(e) le 17-06-1995, ...   \n",
      "2  Je suis Francoise Gosselin, ne(e) le 15-08-199...   \n",
      "3  Je suis Olivier Seguin, ne(e) le 18-10-1995, e...   \n",
      "4  Je suis Alfred Lopes-Dupont, ne(e) le 22-03-19...   \n",
      "\n",
      "                                             profile  \n",
      "0  {'name': 'Honore Allard', 'location': 'Bizerte...  \n",
      "1  {'name': 'Roland Teixeira', 'location': 'Bizer...  \n",
      "2  {'name': 'Francoise Gosselin', 'location': 'Sf...  \n",
      "3  {'name': 'Olivier Seguin', 'location': 'Tunis'...  \n",
      "4  {'name': 'Alfred Lopes-Dupont', 'location': 'S...  \n"
     ]
    }
   ],
   "source": [
    "print(df[['text_clear', 'profile']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a1e03de-5dd5-42a8-ae1e-cfe428115896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clear</th>\n",
       "      <th>entities</th>\n",
       "      <th>profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Je suis Anouk Roche, n√©(e) le 20 March 2001, √©...</td>\n",
       "      <td>Je suis Anouk Roche, ne(e) le 20-03-2001, etud...</td>\n",
       "      <td>{'PER': ['Anouk Roche'], 'LOC': ['Sousse'], 'O...</td>\n",
       "      <td>{'name': 'Anouk Roche', 'location': 'Sousse', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Je suis No√©mi-Anne Buisson, n√©(e) le 8 Februar...</td>\n",
       "      <td>Je suis Noemi-Anne Buisson, ne(e) le 08-02-200...</td>\n",
       "      <td>{'PER': ['Anne Buisson'], 'LOC': ['etudier a F...</td>\n",
       "      <td>{'name': 'Noemi-Anne Buisson', 'location': 'Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Je suis Matthieu Leblanc, n√©(e) le 19 February...</td>\n",
       "      <td>Je suis Matthieu Leblanc, ne(e) le 19-02-1995,...</td>\n",
       "      <td>{'PER': ['Matthieu Leblanc', 'etudiant(e'], 'L...</td>\n",
       "      <td>{'name': 'Matthieu Leblanc', 'location': 'Sfax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Je suis Hortense Robert, n√©(e) le 08/03/1995, ...</td>\n",
       "      <td>Je suis Hortense Robert, ne(e) le 08-03-1995, ...</td>\n",
       "      <td>{'PER': ['Hortense Robert', 'etudiant(e'], 'LO...</td>\n",
       "      <td>{'name': 'Hortense Robert', 'location': 'Sfax'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Je suis Vincent Vidal, n√©(e) le 19/03/1996, √©t...</td>\n",
       "      <td>Je suis Vincent Vidal, ne(e) le 19-03-1996, et...</td>\n",
       "      <td>{'PER': ['Vincent Vidal', 'etudiant(e'], 'LOC'...</td>\n",
       "      <td>{'name': 'Vincent Vidal', 'location': 'Tunis',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "295  Je suis Anouk Roche, n√©(e) le 20 March 2001, √©...   \n",
       "296  Je suis No√©mi-Anne Buisson, n√©(e) le 8 Februar...   \n",
       "297  Je suis Matthieu Leblanc, n√©(e) le 19 February...   \n",
       "298  Je suis Hortense Robert, n√©(e) le 08/03/1995, ...   \n",
       "299  Je suis Vincent Vidal, n√©(e) le 19/03/1996, √©t...   \n",
       "\n",
       "                                            text_clear  \\\n",
       "295  Je suis Anouk Roche, ne(e) le 20-03-2001, etud...   \n",
       "296  Je suis Noemi-Anne Buisson, ne(e) le 08-02-200...   \n",
       "297  Je suis Matthieu Leblanc, ne(e) le 19-02-1995,...   \n",
       "298  Je suis Hortense Robert, ne(e) le 08-03-1995, ...   \n",
       "299  Je suis Vincent Vidal, ne(e) le 19-03-1996, et...   \n",
       "\n",
       "                                              entities  \\\n",
       "295  {'PER': ['Anouk Roche'], 'LOC': ['Sousse'], 'O...   \n",
       "296  {'PER': ['Anne Buisson'], 'LOC': ['etudier a F...   \n",
       "297  {'PER': ['Matthieu Leblanc', 'etudiant(e'], 'L...   \n",
       "298  {'PER': ['Hortense Robert', 'etudiant(e'], 'LO...   \n",
       "299  {'PER': ['Vincent Vidal', 'etudiant(e'], 'LOC'...   \n",
       "\n",
       "                                               profile  \n",
       "295  {'name': 'Anouk Roche', 'location': 'Sousse', ...  \n",
       "296  {'name': 'Noemi-Anne Buisson', 'location': 'Bi...  \n",
       "297  {'name': 'Matthieu Leblanc', 'location': 'Sfax...  \n",
       "298  {'name': 'Hortense Robert', 'location': 'Sfax'...  \n",
       "299  {'name': 'Vincent Vidal', 'location': 'Tunis',...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eb4de92-917a-410d-a56c-7bdbf865d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPANSION : transformer les dictionnaires en colonnes\n",
    "profiles_df = pd.json_normalize(df[\"profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64f6b266-bd48-42c0-bf6a-9f2a79c9c622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>university</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honore Allard</td>\n",
       "      <td>Bizerte</td>\n",
       "      <td>ENIT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>30-01-2005</td>\n",
       "      <td>30-01-2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roland Teixeira</td>\n",
       "      <td>Bizerte</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>17-06-1995</td>\n",
       "      <td>17-06-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Francoise Gosselin</td>\n",
       "      <td>Sfax</td>\n",
       "      <td>ENIT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>15-08-1996</td>\n",
       "      <td>15-08-1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Olivier Seguin</td>\n",
       "      <td>Tunis</td>\n",
       "      <td>ENIT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18-10-1995</td>\n",
       "      <td>18-10-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alfred Lopes-Dupont</td>\n",
       "      <td>Sfax</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>22-03-1998</td>\n",
       "      <td>22-03-1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Anouk Roche</td>\n",
       "      <td>Sousse</td>\n",
       "      <td>ENIT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>20-03-2001</td>\n",
       "      <td>20-03-2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Noemi-Anne Buisson</td>\n",
       "      <td>Bizerte</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>08-02-2007</td>\n",
       "      <td>08-02-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Matthieu Leblanc</td>\n",
       "      <td>Sfax</td>\n",
       "      <td>Universite de Tunis</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19-02-1995</td>\n",
       "      <td>19-02-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Hortense Robert</td>\n",
       "      <td>Sfax</td>\n",
       "      <td>IHEC</td>\n",
       "      <td>unknown</td>\n",
       "      <td>08-03-1995</td>\n",
       "      <td>08-03-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Vincent Vidal</td>\n",
       "      <td>Tunis</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19-03-1996</td>\n",
       "      <td>19-03-1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name location           university    email       phone  \\\n",
       "0          Honore Allard  Bizerte                 ENIT  unknown  30-01-2005   \n",
       "1        Roland Teixeira  Bizerte              unknown  unknown  17-06-1995   \n",
       "2     Francoise Gosselin     Sfax                 ENIT  unknown  15-08-1996   \n",
       "3         Olivier Seguin    Tunis                 ENIT  unknown  18-10-1995   \n",
       "4    Alfred Lopes-Dupont     Sfax              unknown  unknown  22-03-1998   \n",
       "..                   ...      ...                  ...      ...         ...   \n",
       "295          Anouk Roche   Sousse                 ENIT  unknown  20-03-2001   \n",
       "296   Noemi-Anne Buisson  Bizerte              unknown  unknown  08-02-2007   \n",
       "297     Matthieu Leblanc     Sfax  Universite de Tunis  unknown  19-02-1995   \n",
       "298      Hortense Robert     Sfax                 IHEC  unknown  08-03-1995   \n",
       "299        Vincent Vidal    Tunis              unknown  unknown  19-03-1996   \n",
       "\n",
       "      birthdate  \n",
       "0    30-01-2005  \n",
       "1    17-06-1995  \n",
       "2    15-08-1996  \n",
       "3    18-10-1995  \n",
       "4    22-03-1998  \n",
       "..          ...  \n",
       "295  20-03-2001  \n",
       "296  08-02-2007  \n",
       "297  19-02-1995  \n",
       "298  08-03-1995  \n",
       "299  19-03-1996  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3d54670-8e54-495d-a1e6-b0688af58345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profiles.csv g√©n√©r√© avec succ√®s !\n"
     ]
    }
   ],
   "source": [
    "profiles_df.to_csv(\"profiles.csv\", index=False)\n",
    "print(\"profiles.csv g√©n√©r√© avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4dc46-53d7-4388-9555-0c6816caff40",
   "metadata": {},
   "source": [
    "### on est besoin du texte original avant / apres le process de nettoyage et NER NLP technologies \n",
    "car Si j'exporte juste profiles_df, je perd la r√©f√©rence au texte original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7679425e-5189-4d4c-8805-6ad4deb81bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df[\"text\"], profiles_df], axis=1) #concatenation horizantal (axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de5058f7-5437-404f-ad9d-df0fc5ecf6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>university</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>birthdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Je suis Honor√© Allard, n√©(e) le 30 January 200...</td>\n",
       "      <td>Honore Allard</td>\n",
       "      <td>Bizerte</td>\n",
       "      <td>ENIT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>30-01-2005</td>\n",
       "      <td>30-01-2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je suis Roland Teixeira, n√©(e) le 17 June 1995...</td>\n",
       "      <td>Roland Teixeira</td>\n",
       "      <td>Bizerte</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>17-06-1995</td>\n",
       "      <td>17-06-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Je suis Fran√ßoise Gosselin, n√©(e) le 15 August...</td>\n",
       "      <td>Francoise Gosselin</td>\n",
       "      <td>Sfax</td>\n",
       "      <td>ENIT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>15-08-1996</td>\n",
       "      <td>15-08-1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Je suis Olivier Seguin, n√©(e) le 18 October 19...</td>\n",
       "      <td>Olivier Seguin</td>\n",
       "      <td>Tunis</td>\n",
       "      <td>ENIT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>18-10-1995</td>\n",
       "      <td>18-10-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Je suis Alfred Lopes-Dupont, n√©(e) le 22 March...</td>\n",
       "      <td>Alfred Lopes-Dupont</td>\n",
       "      <td>Sfax</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>22-03-1998</td>\n",
       "      <td>22-03-1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Je suis Anouk Roche, n√©(e) le 20 March 2001, √©...</td>\n",
       "      <td>Anouk Roche</td>\n",
       "      <td>Sousse</td>\n",
       "      <td>ENIT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>20-03-2001</td>\n",
       "      <td>20-03-2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Je suis No√©mi-Anne Buisson, n√©(e) le 8 Februar...</td>\n",
       "      <td>Noemi-Anne Buisson</td>\n",
       "      <td>Bizerte</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>08-02-2007</td>\n",
       "      <td>08-02-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Je suis Matthieu Leblanc, n√©(e) le 19 February...</td>\n",
       "      <td>Matthieu Leblanc</td>\n",
       "      <td>Sfax</td>\n",
       "      <td>Universite de Tunis</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19-02-1995</td>\n",
       "      <td>19-02-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Je suis Hortense Robert, n√©(e) le 08/03/1995, ...</td>\n",
       "      <td>Hortense Robert</td>\n",
       "      <td>Sfax</td>\n",
       "      <td>IHEC</td>\n",
       "      <td>unknown</td>\n",
       "      <td>08-03-1995</td>\n",
       "      <td>08-03-1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Je suis Vincent Vidal, n√©(e) le 19/03/1996, √©t...</td>\n",
       "      <td>Vincent Vidal</td>\n",
       "      <td>Tunis</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19-03-1996</td>\n",
       "      <td>19-03-1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text                 name  \\\n",
       "0    Je suis Honor√© Allard, n√©(e) le 30 January 200...        Honore Allard   \n",
       "1    Je suis Roland Teixeira, n√©(e) le 17 June 1995...      Roland Teixeira   \n",
       "2    Je suis Fran√ßoise Gosselin, n√©(e) le 15 August...   Francoise Gosselin   \n",
       "3    Je suis Olivier Seguin, n√©(e) le 18 October 19...       Olivier Seguin   \n",
       "4    Je suis Alfred Lopes-Dupont, n√©(e) le 22 March...  Alfred Lopes-Dupont   \n",
       "..                                                 ...                  ...   \n",
       "295  Je suis Anouk Roche, n√©(e) le 20 March 2001, √©...          Anouk Roche   \n",
       "296  Je suis No√©mi-Anne Buisson, n√©(e) le 8 Februar...   Noemi-Anne Buisson   \n",
       "297  Je suis Matthieu Leblanc, n√©(e) le 19 February...     Matthieu Leblanc   \n",
       "298  Je suis Hortense Robert, n√©(e) le 08/03/1995, ...      Hortense Robert   \n",
       "299  Je suis Vincent Vidal, n√©(e) le 19/03/1996, √©t...        Vincent Vidal   \n",
       "\n",
       "    location           university    email       phone   birthdate  \n",
       "0    Bizerte                 ENIT  unknown  30-01-2005  30-01-2005  \n",
       "1    Bizerte              unknown  unknown  17-06-1995  17-06-1995  \n",
       "2       Sfax                 ENIT  unknown  15-08-1996  15-08-1996  \n",
       "3      Tunis                 ENIT  unknown  18-10-1995  18-10-1995  \n",
       "4       Sfax              unknown  unknown  22-03-1998  22-03-1998  \n",
       "..       ...                  ...      ...         ...         ...  \n",
       "295   Sousse                 ENIT  unknown  20-03-2001  20-03-2001  \n",
       "296  Bizerte              unknown  unknown  08-02-2007  08-02-2007  \n",
       "297     Sfax  Universite de Tunis  unknown  19-02-1995  19-02-1995  \n",
       "298     Sfax                 IHEC  unknown  08-03-1995  08-03-1995  \n",
       "299    Tunis              unknown  unknown  19-03-1996  19-03-1996  \n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "872c457a-7848-4db1-b71d-9a975fb1fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"profiles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cffeeb8-c2e2-4b6e-9f28-99904f90f730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7fe96a-3c4e-4331-884c-3e4b4491d943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd637a86-bda2-44b6-adf1-83e024fbc7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d2f43-e674-4270-a1fd-ad680d177a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
